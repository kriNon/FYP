{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "\n",
    "import pandas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "#from pushover import notify\n",
    "from sksq96Utils import makegif\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=1024, z_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size())\n",
    "        esp = esp.to(device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels = 3\n",
    "model = VAE(image_channels=image_channels).to(device)\n",
    "model.load_state_dict(torch.load('vae.torch', map_location=device))\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomDatasetFromFile(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        \"\"\"\n",
    "        A dataset example where the class is embedded in the file names\n",
    "        This data example also does not use any torch transforms\n",
    "\n",
    "        Args:\n",
    "            folder_path (string): path to image folder\n",
    "        \"\"\"\n",
    "        # Get image list\n",
    "        self.image_list = glob.glob(folder_path+'*')\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.image_list)\n",
    "        self.num_samples = self.data_len\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        from PIL import Image\n",
    "        # Get image name from the pandas df\n",
    "        single_image_path = self.image_list[index]\n",
    "        \n",
    "        ImageNameDataList = single_image_path[39:-4].split(\"_\")\n",
    "        imageGroupNumber = ImageNameDataList[0]\n",
    "        imageFrameNumber = ImageNameDataList[1]\n",
    "        prevFrameNumber = max(1,int(imageFrameNumber)-1)\n",
    "        \n",
    "        previous_image_path2 = glob.glob(f'D:/Kris\\'s Workbench/FYP/TrainingData/0/'+str(imageGroupNumber)+'_'+str(prevFrameNumber)+'_'+'*')[0]\n",
    "            \n",
    "        # Open image\n",
    "        im_as_im = Image.open(single_image_path)\n",
    "        previousim_as_im = Image.open(previous_image_path2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        preprocess=transforms.Compose([\n",
    "            transforms.Resize(64),\n",
    "            transforms.ToTensor(), \n",
    "            ])\n",
    "        im_preprocessed = preprocess(im_as_im)\n",
    "        previousim_preprocessed = preprocess(previousim_as_im)\n",
    "        \n",
    "        return (im_preprocessed,previousim_preprocessed,ImageNameDataList[2:5])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDatasetFromFile(folder_path=f'D:/Kris\\'s Workbench/FYP/TrainingData/0/')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed input for debugging\n",
    "CurrentImage, PreviousImage, _ = next(iter(dataloader))\n",
    "curr, _, _ = model.encode(CurrentImage.to(device))\n",
    "prev, _, _ = model.encode(PreviousImage.to(device))\n",
    "concatenatedTensor = torch.cat((prev, curr), 0)\n",
    "\n",
    "def decodeConcatenatedTensor(Tensor):\n",
    "    a, b = concatenatedTensor.split(32, dim=0)\n",
    "    aDecoded = model.decode(a)\n",
    "    bDecoded = model.decode(b)\n",
    "    save_image(aDecoded[0], 'imagea.png')\n",
    "    save_image(aDecoded[0], 'imageb.png')\n",
    "    \n",
    "\n",
    "\n",
    "decodeConcatenatedTensor(concatenatedTensor)\n",
    "from IPython.display import Image\n",
    "Image(filename='imagea.png')\n",
    "\n",
    "# print(a.shape)\n",
    "# print(b.shape)\n",
    "# recon_images = model.decode(b)\n",
    "# save_image(recon_images[0], 'test_image.png')\n",
    "# from IPython.display import Image\n",
    "# Image(filename='test_image.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Image(filename='imageb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32])\n"
     ]
    }
   ],
   "source": [
    "#Neural Network Parameters\n",
    "num_epochs = 5\n",
    "batch_size = bs\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 64*32 #Dimensions of the input \"concatenatedTensor\"\n",
    "hidden_size = 600\n",
    "num_classes = 3 #Three state outputs. Acceleration. Braking. Turning Angle\n",
    "\n",
    "print(concatenatedTensor.shape)\n",
    "\n",
    "#Define neural network for this part\n",
    "class StateDetectionNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(StateDetectionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() #Do we use RelU because linear maths is fast on gpu? Or is there some other benefit over sigmoid / alternatives?\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x.reshape(-1,input_size))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model2 = StateDetectionNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "#Define loss and optimizer\n",
    "loss = nn.CrossEntropyLoss()#mean squared error or l1 loss\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'stack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-da0e8b464813>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcatenatedTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatevariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'stack'"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (CurrentImage, PreviousImage, statevariables) in enumerate(dataloader):\n",
    "        CurrentImage = CurrentImage.to(device)\n",
    "        PreviousImage = PreviousImage.to(device)\n",
    "        curr, _, _ = model.encode(CurrentImage.to(device))\n",
    "        prev, _, _ = model.encode(PreviousImage.to(device))\n",
    "        concatenatedTensor = torch.cat((prev, curr), 0)\n",
    "        \n",
    "        out = model2(concatenatedTensor)\n",
    "        loss = loss(out, statevariables)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #to_print = \"Loss: {:.3f} {:.3f} {:.3f}\".format(loss.data.item()/bs, bce.data.item()/bs, kld.data.item()/bs)\n",
    "        \n",
    "        #\n",
    "    to_print = \"Epoch[{}/{}] Loss: {:.3f} {:.3f} {:.3f}\".format(epoch+1,epochs, loss.data.item()/bs, bce.data.item()/bs, kld.data.item()/bs)\n",
    "    print(to_print)\n",
    "    #print(epoch)\n",
    "\n",
    "# notify to android when finished training\n",
    "# notify(to_print, priority=1)\n",
    "\n",
    "torch.save(model.state_dict(), 'CurrentConditions.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
